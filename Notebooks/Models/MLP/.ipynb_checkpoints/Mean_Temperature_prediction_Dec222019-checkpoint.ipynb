{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate MLP Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multilayer Perceptrons, or MLPs for short, can be used to model univariate time series forecasting\n",
    "problems. Univariate time series are a dataset comprised of a single series of observations with\n",
    "a temporal ordering and a model is required to learn from the series of past observations to\n",
    "predict the next value in the sequence. This section is divided into two parts; they are:\n",
    "\n",
    "1. Data Preparation\n",
    "2. MLP Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before a univariate series can be modeled, it must be prepared. The MLP model will learn a\n",
    "function that maps a sequence of past observations as input to an output observation. As such,\n",
    "the sequence of observations must be transformed into multiple examples from which the model\n",
    "can learn. Consider a given univariate sequence:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Img_1](Imgs/sequence.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can divide the sequence into multiple input/output patterns called samples, where three\n",
    "time steps are used as input and one time step is used as output for the one-step prediction\n",
    "that is being learned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21 17 17] 20\n",
      "[17 17 20] 18\n",
      "[17 20 18] 21\n",
      "[20 18 21] 19\n",
      "[18 21 19] 19\n",
      "[21 19 19] 22\n",
      "[19 19 22] 18\n",
      "[19 22 18] 13\n",
      "[22 18 13] 12\n",
      "[18 13 12] 19\n",
      "[13 12 19] 23\n",
      "[12 19 23] 25\n",
      "[19 23 25] 25\n",
      "[23 25 25] 14\n",
      "[25 25 14] 9\n",
      "[25 14  9] 10\n",
      "[14  9 10] 13\n",
      "[ 9 10 13] 13\n"
     ]
    }
   ],
   "source": [
    "# univariate data preparation\n",
    "from numpy import array\n",
    "\n",
    "# split a univariate sequence into samples\n",
    "def split_sequence(sequence, n_steps):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequence)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps\n",
    "        # check if we are beyond the sequence\n",
    "        if end_ix > len(sequence)-1:\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return array(X), array(y)\n",
    "\n",
    "# define input sequence (Monterrey's Temperature in °C from Dec 1st - Dec 21st)\n",
    "raw_seq = [21, 17, 17, 20, 18, 21, 19, 19, 22, 18,13, 12, 19, 23, 25, 25, 14, 9, 10, 13, 13]\n",
    "# choose a number of time steps\n",
    "n_steps = 3\n",
    "# split into samples\n",
    "X, y = split_sequence(raw_seq, n_steps)\n",
    "# summarize the data\n",
    "for i in range(len(X)):\n",
    "    print(X[i], y[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the example above splits the univariate series into six samples where each sample has\n",
    "three input time steps and one output time step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know how to prepare a univariate series for modeling, let’s look at developing\n",
    "an MLP model that can learn the mapping of inputs to outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. MLP Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple MLP model has a single hidden layer of nodes, and an output layer used to make a\n",
    "prediction. We can define an MLP for univariate time series forecasting as follows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# univariate mlp example\n",
    "from numpy import array\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# define model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(100, activation= 'relu' , input_dim=n_steps))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer= 'adam' , loss= 'mse' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important in the definition is the shape of the input; that is what the model expects as\n",
    "input for each sample in terms of the number of time steps. The number of time steps as input\n",
    "is the number we chose when preparing our dataset as an argument to the `split sequence()`\n",
    "function. The input dimension for each sample is specified in the input dim argument on the\n",
    "definition of first hidden layer. Technically, the model will view each time step as a separate\n",
    "feature instead of separate time steps.\n",
    "We almost always have multiple samples, therefore, the model will expect the input\n",
    "component of training data to have the dimensions or shape: ```[samples, features]```. Our\n",
    "split sequence() function in the previous section outputs the X with the shape `[samples,features]` ready to use for modeling. The model is fit using the efficient Adam version of\n",
    "stochastic gradient descent and optimized using the mean squared error, or ‘mse’, loss function.\n",
    "Once the model is defined, we can fit it on the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f57503f0fd0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model\n",
    "model.fit(X, y, epochs=2000, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the model is fit, we can use it to make a prediction. We can predict the next value\n",
    "in the sequence by providing the input: `[70, 80, 90]`. And expecting the model to predict\n",
    "something like: `[100]`. The model expects the input shape to be two-dimensional with `[samples,\n",
    "features]`, therefore, we must reshape the single input sample before making the prediction,\n",
    "e.g with the shape `[1, 3]` for 1 sample and 3 time steps used as input features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[14.599053]]\n"
     ]
    }
   ],
   "source": [
    "# mean temperature of Dec 22 2019 prediction:\n",
    "x_input = array([10, 13, 13])\n",
    "x_input = x_input.reshape((1, n_steps))\n",
    "yhat = model.predict(x_input, verbose=0)\n",
    "\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can tie all of this together and demonstrate how to develop an MLP for univariate time\n",
    "series forecasting and make a single prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[100.00855]]\n"
     ]
    }
   ],
   "source": [
    "# univariate mlp example\n",
    "from numpy import array\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# split a univariate sequence into samples\n",
    "def split_sequence(sequence, n_steps):\n",
    "    X, y = list(), list()\n",
    "    \n",
    "    for i in range(len(sequence)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps\n",
    "        \n",
    "        # check if we are beyond the sequence\n",
    "        if end_ix > len(sequence)-1:\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "\n",
    "    return array(X), array(y)\n",
    "\n",
    "# define input sequence\n",
    "raw_seq = [10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
    "\n",
    "# choose a number of time steps\n",
    "n_steps = 3\n",
    "\n",
    "# split into samples\n",
    "X, y = split_sequence(raw_seq, n_steps)\n",
    "\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Dense(100, activation= 'relu' , input_dim=n_steps))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer= 'adam' , loss= 'mse' )\n",
    "\n",
    "# fit model\n",
    "model.fit(X, y, epochs=2000, verbose=0)\n",
    "\n",
    "# demonstrate prediction\n",
    "x_input = array([70, 80, 90])\n",
    "x_input = x_input.reshape((1, n_steps))\n",
    "yhat = model.predict(x_input, verbose=0)\n",
    "\n",
    "print(yhat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
